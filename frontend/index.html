<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <title>Reading360 - GrabaciÃ³n de voz</title>
</head>
<body>
  <h1>ğŸ™ï¸ Reading360</h1>
  <p>Haz clic en grabar, lee el texto en voz alta y luego envÃ­a el audio para analizarlo.</p>

  <button id="startBtn">ğŸ”´ Grabar</button>
  <button id="stopBtn" disabled>â¹ï¸ Detener</button>
  <button id="sendBtn" disabled>ğŸ“¤ Enviar</button>

  <audio id="audioPlayback" controls></audio>

  <script>
    let mediaRecorder;
    let audioChunks = [];

    const startBtn = document.getElementById("startBtn");
    const stopBtn = document.getElementById("stopBtn");
    const sendBtn = document.getElementById("sendBtn");
    const audioPlayback = document.getElementById("audioPlayback");

    startBtn.onclick = async () => {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder = new MediaRecorder(stream);
      audioChunks = [];

      mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
      mediaRecorder.onstop = () => {
        const audioBlob = new Blob(audioChunks, { type: "audio/wav" });
        audioPlayback.src = URL.createObjectURL(audioBlob);
        sendBtn.disabled = false;
      };

      mediaRecorder.start();
      startBtn.disabled = true;
      stopBtn.disabled = false;
    };

    stopBtn.onclick = () => {
      mediaRecorder.stop();
      startBtn.disabled = false;
      stopBtn.disabled = true;
    };
  </script>
  
<script>
  let latestVoiceMetrics = null;
  let latestVisualMetrics = null;
  const sessionId = Date.now().toString(); // ID Ãºnico por sesiÃ³n
  let readingRegistered = false; // âœ… bandera para evitar mÃºltiples registros

  sendBtn.onclick = async () => {
    const audioBlob = new Blob(audioChunks, { type: "audio/wav" });
    const formData = new FormData();
    formData.append("audio", audioBlob, "lectura.wav");

    const response = await fetch("/upload-audio", {
      method: "POST",
      body: formData
    });

    const voiceResult = await response.json();
    latestVoiceMetrics = voiceResult;
    alert("âœ… Voz analizada:\n" + JSON.stringify(voiceResult, null, 2));

    tryRegisterReading(); // âœ… intenta registrar si ya hay datos visuales
  };

  async function tryRegisterReading() {
    if (readingRegistered) return; // âœ… evita duplicaciÃ³n
    if (!latestVoiceMetrics || !latestVisualMetrics) {
      console.log("â³ Esperando ambos anÃ¡lisis para registrar...");
      return;
    }

    const readingData = {
      session_id: sessionId,
      user_id: "demo_user",
      text_id: "demo_text",
      label: "unlabeled",
      voice: latestVoiceMetrics,
      visual: latestVisualMetrics
    };

    const res = await fetch("/register-reading", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(readingData)
    });

    const result = await res.json();
    alert("ğŸ“š Lectura registrada:\n" + JSON.stringify(result, null, 2));
    readingRegistered = true; // âœ… marca como registrada
  }
</script>


  <h2>ğŸ‘ï¸ Seguimiento facial</h2>
<video id="video" autoplay muted playsinline width="320" height="240" style="border:1px solid #ccc;"></video>
<canvas id="output" width="320" height="240" style="position:absolute; left:0; top:0;"></canvas>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>

<script>
  const videoElement = document.getElementById('video');
  const canvasElement = document.getElementById('output');
  const canvasCtx = canvasElement.getContext('2d');

  const faceMesh = new FaceMesh({
    locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
  });

  faceMesh.setOptions({
    maxNumFaces: 1,
    refineLandmarks: true,
    minDetectionConfidence: 0.5,
    minTrackingConfidence: 0.5
  });

let lastSent = 0;

faceMesh.onResults(results => {
  const now = Date.now();
  if (now - lastSent < 2000) return; // espera 2 segundos entre envÃ­os

  canvasCtx.save();
  canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
  canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

  if (results.multiFaceLandmarks) {
    for (const landmarks of results.multiFaceLandmarks) {
      drawConnectors(canvasCtx, landmarks, FACEMESH_TESSELATION, { color: '#C0C0C0', lineWidth: 1 });
      drawConnectors(canvasCtx, landmarks, FACEMESH_RIGHT_EYE, { color: '#FF3030' });
      drawConnectors(canvasCtx, landmarks, FACEMESH_LEFT_EYE, { color: '#30FF30' });

      const gazePoints = landmarks.map(p => ({ x: p.x, y: p.y }));

      fetch("/upload-visual", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ gazePoints })
      }).then(res => res.json())
        .then(data => {
            latestVisualMetrics = data;
            console.log("âœ… AtenciÃ³n visual:", data);
            tryRegisterReading();
        })
         .catch(err => console.error("âŒ Error al enviar datos visuales:", err));

      lastSent = now;
    }
  }

  canvasCtx.restore();
});

</script>
</body>
</html>
